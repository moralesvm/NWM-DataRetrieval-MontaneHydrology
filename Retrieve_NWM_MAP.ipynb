{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a405349-2ece-45e4-bcc7-2c35fd04c788",
   "metadata": {},
   "source": [
    "## Retrieve NWM retrospective mean spatial precipitation (MAP) from version 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b3f29d-62b4-431f-8f50-e410e5d48224",
   "metadata": {},
   "source": [
    "* This code retrieves precipitation data from the NWM retrospective dataset stored in AWS (https://registry.opendata.aws/nwm-archive/) and computes the average over a basin area. \n",
    "* Basin area is defined by a shapefile poligon.\n",
    "* This code was adapted from Garousi-Nejad, I., A. M. Castronova (2024). Analysis of precipitation data across the Logan River Watershed for the Year 2010, HydroShare, http://www.hydroshare.org/resource/b1379f00121e456f958f9e22e913aa8a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faab486-356d-42b5-b0b5-ae7b9e61c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import xarray\n",
    "import s3fs\n",
    "import hvplot.xarray\n",
    "import geopandas\n",
    "import numpy\n",
    "import pyproj\n",
    "import rioxarray \n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import contextily as cx\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f66aa9-96ba-4db8-ad67-9bdc27cd5e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the recipitation data lives\n",
    "s3_path = 's3://noaa-nwm-retrospective-2-1-zarr-pds/precip.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a542fc5-2c4d-4312-94b5-1f515d33f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to S3\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "store = s3fs.S3Map(root=s3_path, s3=s3, check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc51ac-3263-4b40-8071-677ae15a2f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load the dataset\n",
    "ds = xarray.open_zarr(store=store, consolidated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde514c-ba96-43b7-b451-f207e24c493e",
   "metadata": {},
   "source": [
    "#### Defining projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb3354-f3ed-42f2-aa6e-12acd81cf95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 2D grid of coordinate values\n",
    "X, Y = numpy.meshgrid(ds.x.values, ds.y.values)\n",
    "\n",
    "# define the input crs\n",
    "wrf_proj = pyproj.Proj(proj='lcc',\n",
    "                       lat_1=30.,\n",
    "                       lat_2=60., \n",
    "                       lat_0=40.0000076293945, lon_0=-97., # Center point\n",
    "                       a=6370000, b=6370000) \n",
    "\n",
    "# Define the output crs\n",
    "wgs_proj = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "\n",
    "# transform X, Y into Lat, Lon\n",
    "transformer = pyproj.Transformer.from_crs(wrf_proj.crs, wgs_proj.crs)\n",
    "lon, lat = transformer.transform(X, Y)\n",
    "\n",
    "# add geographical coordinate values (log and lat) to the dataset\n",
    "ds = ds.assign_coords(lon = (['y', 'x'], lon))\n",
    "ds = ds.assign_coords(lat = (['y', 'x'], lat))\n",
    "\n",
    "#add crs to file\n",
    "ds.rio.write_crs(ds.crs.attrs['spatial_ref'], inplace=True\n",
    "                ).rio.set_spatial_dims(x_dim=\"x\",\n",
    "                                       y_dim=\"y\",\n",
    "                                       inplace=True,\n",
    "                                       ).rio.write_coordinate_system(inplace=True)\n",
    "\n",
    "# make sure the data is sorted by time\n",
    "ds = ds.sortby('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c052c43-1c20-4184-944e-1dd9d91dab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a target coordinate system to convert the geometry data into the projection of our forcing data\n",
    "target_crs = wrf_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aac9c2-3f2a-40c7-83f1-4167780d8e5b",
   "metadata": {},
   "source": [
    "#### Test of MAP computation with one basin [optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3247323-4d9f-492e-96d8-e9a4a482cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timerange = slice('2011-04-28 17:00:00','2011-04-28 17:00:00')\n",
    "max_lon = ds[\"x\"].max()\n",
    "max_lat = ds[\"y\"].max()\n",
    "dat = ds.sel(time=timerange,x=slice(1e6,max_lon),y=slice(0,max_lat)).RAINRATE.persist() # Only the NE US\n",
    "#dat = ds.sel(time=timerange).RAINRATE.persist() # Full CONUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3de498c-f141-4546-a49d-28b3ae18c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713425bf-32e4-4c23-8a74-0779db3e03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load basin shapefile\n",
    "shp_path = './Input/Shp/'\n",
    "fname = 'ST_W5.shp'\n",
    "shapefile = shp_path+fname\n",
    "\n",
    "shp = geopandas.read_file(shapefile)\n",
    "shp_crs = shp.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09316c3-aba2-4131-b9aa-b3fa5728f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx.providers.CartoDB.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b257fa-47bb-4233-a7d9-566fce70e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = shp.plot(figsize=(9, 9), alpha=0.5, edgecolor='k')\n",
    "cx.add_basemap(ax,crs=shp.crs,source=cx.providers.CartoDB.Voyager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff004034-addb-4476-85f8-ffe931eea8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject basins to AORC projection\n",
    "shp_prj = shp.to_crs(target_crs.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db8247-1f3a-4837-9d23-2fcbf419d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this method all the pixels that are touched in any % by the limit are included\n",
    "clipped = dat.rio.clip(shp_prj.geometry, all_touched=True, drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a542e11-f504-43e4-987c-b0727a5935aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this method if the centroid is not within the limit, the cell is not included\n",
    "clipped = dat.rio.clip(shp_prj.geometry.values,\n",
    "                 shp_prj.crs,\n",
    "                 drop=True,\n",
    "                 invert=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac156fbe-9a69-4d82-9548-a1a02482778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute spatial mean\n",
    "map = clipped.groupby(\"time\").mean([\"y\", \"x\"])\n",
    "map.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab673d9-d651-4040-b2e4-bcdefac1e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to double check the result\n",
    "f, ax = plt.subplots(1,figsize=(9, 9))\n",
    "clipped.plot(ax=ax)\n",
    "shp_prj.plot(ax=ax,cmap=None,facecolor=\"none\", edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c700b6-01d4-4bbd-b26b-67d91be60fcf",
   "metadata": {},
   "source": [
    "#### Get MAP values for all basins over the full retrospective period by time chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb31be42-3101-4c8b-ac2f-9571b791729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice all data in time chunks\n",
    "start_date = datetime.strptime(\"1979-02-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "end_date = datetime.strptime(\"2021-01-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "date_list = pandas.date_range(start_date, end_date, periods=11) # Adjust number of periods as needed\n",
    "date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b09561-280b-4a84-82b2-37126e60a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting paths and names\n",
    "shp_path = './Input/Shp/'\n",
    "savePath = './Output/'\n",
    "bsns_name = [\"ST_RB\",\"ST_W3\",\"ST_W5\",\"ST_WB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538fe24-b9b2-4560-a21c-9360eddd0aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to process the data in time chunks\n",
    "max_lon = ds[\"x\"].max()\n",
    "max_lat = ds[\"y\"].max()\n",
    "\n",
    "for i in range(len(date_list)-1):\n",
    "    print(\"Processing block of dates from\",date_list[i], \"to\",date_list[i+1])\n",
    "    timerange = slice(str(date_list[i]), str(date_list[i+1]))\n",
    "    print(timerange)\n",
    "    dat = ds.sel(time=timerange,x=slice(1e6,max_lon),y=slice(0,max_lat)).RAINRATE.persist()\n",
    "    \n",
    "    # Loop through the sites\n",
    "    for name in bsns_name:\n",
    "        shapefile = (shp_path+name+\".shp\")\n",
    "        print(shapefile)\n",
    "        shp = geopandas.read_file(shapefile)\n",
    "        \n",
    "        # Reproject shapefile to AORC projection\n",
    "        shp_prj = shp.to_crs(target_crs.crs)\n",
    "        \n",
    "        # Clip or extract the data within the basin\n",
    "        clipped = dat.rio.clip(shp_prj.geometry.values,shp_prj.crs,drop=True,invert=False)\n",
    "        \n",
    "        # Calculate spatial mean per basin\n",
    "        mean_sprecip = clipped.groupby(\"time\").mean([\"y\", \"x\"]).to_dataframe()\n",
    "        \n",
    "        # Add a column the basin identifier\n",
    "        mean_sprecip['Basin'] = name\n",
    "        \n",
    "        # Save as csv\n",
    "        mean_sprecip.to_csv(f'{savePath}NWM_AORC_MAP_{name}_{str(i)}.csv')\n",
    "        print(\"Saving data...Done\")\n",
    "        \n",
    "        # Delete unnecesary data to save memory\n",
    "    del(clipped,dat,mean_sprecip) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nwm-env]",
   "language": "python",
   "name": "conda-env-nwm-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
