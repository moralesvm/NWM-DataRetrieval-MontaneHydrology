{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a57be4-9772-4401-b05b-2ead049fcad1",
   "metadata": {},
   "source": [
    "## Retrieve NWM retrospective precipitation forcing data (Grid-to-point) from version 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6db756-3e58-4290-bb9d-dfae5c6c3d3c",
   "metadata": {},
   "source": [
    "* This code retrieves precipitation data from the NWM retrospective dataset stored in AWS (https://registry.opendata.aws/nwm-archive/). \n",
    "* The values are extracted from the grid cell that matches a lat/lon location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43e366-9220-4c5c-a7d7-66c2a1ed0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xarray\n",
    "import numpy\n",
    "import pyproj\n",
    "import s3fs\n",
    "from datetime import datetime\n",
    "import hvplot.xarray\n",
    "import dask.array as da\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056d09b-11de-4f39-a6aa-543574aa3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the precipitation data lives\n",
    "s3_path = 's3://noaa-nwm-retrospective-2-1-zarr-pds/precip.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf0698-89e2-4f82-a593-acb711df0043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to S3\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "store = s3fs.S3Map(root=s3_path, s3=s3, check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5039c-367a-42a2-8833-acf6a9425387",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load the dataset\n",
    "ds = xarray.open_zarr(store=store, consolidated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d151d-687f-46a4-bb0c-8717f26d392a",
   "metadata": {},
   "source": [
    "#### Define lat/lon locations where data will be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c8c44-99f7-486a-a0a3-a32644dfc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitesPath = './Input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae75097-b10d-4d52-a9ac-44208584624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv with multiple lat/lon locations\n",
    "#------------------------------------------\n",
    "sites_loc = pd.read_csv(sitesPath+'selStn_precip.csv',dtype={'siteID': 'string','name':'string','Source': 'string'})\n",
    "lat = sites_loc['latitude'].values.tolist()\n",
    "lon = sites_loc['longitude'].values.tolist()\n",
    "siteIDs = sites_loc['siteID'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79055db4-c1cb-424d-96d3-9d1fd0035634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input crs\n",
    "wrf_proj = pyproj.Proj(proj='lcc',\n",
    "                       lat_1=30.,\n",
    "                       lat_2=60., \n",
    "                       lat_0=40.0000076293945, lon_0=-97., # Center point\n",
    "                       a=6370000, b=6370000) \n",
    "\n",
    "# define a target coordinate system to convert locations into the projection of our forcing data\n",
    "target_crs = wrf_proj\n",
    "\n",
    "# Obs proj.\n",
    "wgs_proj = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "\n",
    "# Define transformer to reproject the station locations to the coordinates of AORC/NWM\n",
    "transformer = pyproj.Transformer.from_crs(wgs_proj.crs, target_crs.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b56f54-fefc-4ef8-b73b-56bc2a27a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = numpy.array([siteIDs])\n",
    "\n",
    "# Reproject to AORC/NWM coordinates\n",
    "xx0, yy0 = transformer.transform(lon,lat)\n",
    "\n",
    "xx = xarray.DataArray(xx0, coords=sites, dims=['location'])\n",
    "yy = xarray.DataArray(yy0, coords=sites, dims=['location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f71b9c5-c517-4137-8fbe-8b96f601d8ed",
   "metadata": {},
   "source": [
    "* [OPTIONAL] Add lat/lon coordinates to the NWM dataset (used for plotting and additional reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20a0e3-aa49-406b-ba47-2b61ceab69b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 2D grid of coordinate values\n",
    "X, Y = numpy.meshgrid(ds.x.values, ds.y.values)\n",
    "\n",
    "# transform X, Y into Lat, Lon\n",
    "transformer = pyproj.Transformer.from_crs(wrf_proj.crs, wgs_proj.crs)\n",
    "lon, lat = transformer.transform(X, Y)\n",
    "\n",
    "# add geographical coordinate values (log and lat) to the dataset\n",
    "ds = ds.assign_coords(lon = (['y', 'x'], lon))\n",
    "ds = ds.assign_coords(lat = (['y', 'x'], lat))\n",
    "\n",
    "#add crs to file\n",
    "ds.rio.write_crs(ds.crs.attrs['spatial_ref'], inplace=True\n",
    "                ).rio.set_spatial_dims(x_dim=\"x\",\n",
    "                                       y_dim=\"y\",\n",
    "                                       inplace=True,\n",
    "                                       ).rio.write_coordinate_system(inplace=True)\n",
    "\n",
    "# make sure the data is sorted by time\n",
    "ds = ds.sortby('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b806c2-a96e-4230-94b4-9bbab91d2bd6",
   "metadata": {},
   "source": [
    "#### Extract data over the full retrospective period by time chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7535b8f2-2534-4af8-b5e0-5ed2822f5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "savePath = \"./Output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b9a8de-5bf3-433c-aa9e-7ee53fbd7f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice all data in time chunks\n",
    "start_date = datetime.strptime(\"1979-02-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "end_date = datetime.strptime(\"2021-01-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "date_list = pd.date_range(start_date, end_date, periods=11) # Adjust number of periods as needed\n",
    "print(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002689f9-9268-4ff0-9e6a-06dd20db4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loop to process the data in time chunks\n",
    "max_lon = ds[\"x\"].max()\n",
    "max_lat = ds[\"y\"].max()\n",
    "\n",
    "for i in range(len(date_list)-1):\n",
    "    print(\"Processing block of dates from\",date_list[i], \"to\",date_list[i+1])\n",
    "    timerange = slice(str(date_list[i]), str(date_list[i+1]))\n",
    "    print(timerange)\n",
    "    dat = ds.sel(time=timerange,x=slice(1e6,max_lon),y=slice(0,max_lat)).RAINRATE.persist()\n",
    "    \n",
    "    # Extract the values at the point locations\n",
    "    values_temp = dat.sel(x=xx, y=yy, method='nearest').to_dataframe()\n",
    "    values_temp.to_csv(f'{savePath}NWM_GTPprecipretro_{str(i)}.csv')\n",
    "    print(\"Data saved...Done\")\n",
    "    \n",
    "    # Delete unnecesary data to save memory\n",
    "    del(dat,values_temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwm-env",
   "language": "python",
   "name": "nwm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
